package xjson

import (
	"testing"
)

func TestUltimateCoverageChallenge(t *testing.T) {
	// æœ€åå†²åˆºï¼šå°è¯•çªç ´95%

	// é’ˆå¯¹ String() å‡½æ•° (Result.String) çš„ 75% è¦†ç›–ç‡
	t.Run("String_UltimateAttempt", func(t *testing.T) {
		// å°è¯•å„ç§å¯èƒ½å¯¼è‡´ json.Marshal å¤±è´¥çš„åœºæ™¯
		// è™½ç„¶åœ¨æ­£å¸¸ JSON è§£æçš„ Result ä¸­å¾ˆéš¾é‡åˆ°ï¼Œä½†æˆ‘ä»¬å¯ä»¥æ„é€ ç‰¹æ®Šæƒ…å†µ

		// æµ‹è¯•åŒ…å«æ— ç©·å¤§æˆ– NaN çš„æ•°æ®ï¼ˆè™½ç„¶ JSON ä¸æ”¯æŒï¼Œä½†å¯èƒ½å­˜åœ¨äºå†…å­˜ä¸­ï¼‰
		// ç”±äº JSON è§£æä¸ä¼šäº§ç”Ÿè¿™äº›å€¼ï¼Œæˆ‘ä»¬æµ‹è¯•å…¶ä»–è¾¹ç•Œæƒ…å†µ

		// æµ‹è¯•æå…¶å¤æ‚çš„åµŒå¥—ç»“æ„
		complexData := map[string]interface{}{
			"level1": map[string]interface{}{
				"level2": []interface{}{
					map[string]interface{}{
						"level3": map[string]interface{}{
							"data": []interface{}{1, 2, 3, 4, 5},
						},
					},
				},
			},
		}

		result := &Result{matches: []interface{}{complexData}}
		str, err := result.String()
		if err != nil {
			t.Errorf("String() on complex nested structure should succeed, got error: %v", err)
		}
		if len(str) < 10 {
			t.Error("String() should return substantial JSON for complex structure")
		}

		// æµ‹è¯•åŒ…å« nil çš„ slice
		sliceWithNil := []interface{}{1, nil, "test", nil, 42}
		result2 := &Result{matches: []interface{}{sliceWithNil}}
		str2, err2 := result2.String()
		if err2 != nil {
			t.Errorf("String() on slice with nil should succeed, got error: %v", err2)
		}
		if str2 == "" {
			t.Error("String() should return non-empty JSON for slice with nil")
		}

		// æµ‹è¯•ç©ºæ¥å£åˆ‡ç‰‡
		emptyInterface := []interface{}{}
		result3 := &Result{matches: []interface{}{emptyInterface}}
		str3, err3 := result3.String()
		if err3 != nil {
			t.Errorf("String() on empty interface slice should succeed, got error: %v", err3)
		}
		if str3 != "[]" {
			t.Errorf("String() on empty slice should return '[]', got '%s'", str3)
		}
	})

	// é’ˆå¯¹ Query() å‡½æ•°çš„ 80% è¦†ç›–ç‡
	t.Run("Query_UltimateAttempt", func(t *testing.T) {
		// å°è¯•è§¦å‘æ‰€æœ‰å¯èƒ½çš„ä»£ç è·¯å¾„

		// æµ‹è¯•åœ¨æ— æ•ˆæ–‡æ¡£ä¸Šçš„æŸ¥è¯¢ï¼ˆé”™è¯¯ä¼ æ’­ï¼‰
		doc := &Document{err: ErrInvalidJSON}
		result := doc.Query("/any/path/here")
		if result.Exists() {
			t.Error("Query on invalid document should not exist")
		}

		// æµ‹è¯•ç©ºå­—ç¬¦ä¸²æŸ¥è¯¢ï¼ˆå¯èƒ½æœ‰ç‰¹æ®Šå¤„ç†ï¼‰
		doc2, _ := ParseString(`{"": "empty_key", "normal": "value"}`)
		result2 := doc2.Query("")
		t.Logf("Empty string query exists: %v", result2.Exists())

		// æµ‹è¯•åªæœ‰ç‚¹å·çš„æŸ¥è¯¢
		result3 := doc2.Query("/")
		t.Logf("Dot query exists: %v", result3.Exists())

		// æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æŸ¥è¯¢
		doc3, _ := ParseString(`{"key-with-dashes": 1, "key_with_underscores": 2, "key with spaces": 3}`)

		result4 := doc3.Query("/key-with-dashes")
		if !result4.Exists() {
			t.Log("Dashed key query failed (may need escaping)")
		}

		result5 := doc3.Query("/key_with_underscores")
		if !result5.Exists() {
			t.Error("Underscore key query should succeed")
		}

		// æµ‹è¯•æé•¿çš„æŸ¥è¯¢è·¯å¾„
		longPath := "/level1/level2/level3/level4/level5/level6/level7/level8/level9/level10"
		doc4, _ := ParseString(`{"level1":{"level2":{"level3":{"level4":{"level5":{"level6":{"level7":{"level8":{"level9":{"level10":"deep_value"}}}}}}}}}}`)
		result6 := doc4.Query(longPath)
		if !result6.Exists() {
			t.Error("Long path query should succeed")
		}
	})

	// é’ˆå¯¹ Set/Delete 87.5% è¦†ç›–ç‡
	t.Run("SetDelete_UltimateAttempt", func(t *testing.T) {
		// æµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µ

		// åœ¨å®Œå…¨ç©ºçš„æ–‡æ¡£ä¸Šè®¾ç½®
		doc, _ := ParseString(`{}`)

		// æµ‹è¯•è®¾ç½®æ ¹çº§åˆ«
		err1 := doc.Set("/new_root_key", "root_value")
		if err1 != nil {
			t.Errorf("Set new root key should succeed, got error: %v", err1)
		}

		// æµ‹è¯•è®¾ç½®åµŒå¥—è·¯å¾„ï¼ˆè·¯å¾„ä¸å­˜åœ¨ï¼‰
		err2 := doc.Set("/new/nested/deep/path", "nested_value")
		if err2 != nil {
			t.Errorf("Set new nested path should succeed, got error: %v", err2)
		}

		// æµ‹è¯•åˆ é™¤ä¸å­˜åœ¨çš„è·¯å¾„
		err3 := doc.Delete("/nonexistent/path")
		if err3 == nil {
			t.Log("Delete nonexistent path succeeded (implementation may allow this)")
		} else {
			t.Log("Delete nonexistent path failed (expected)")
		}

		// æµ‹è¯•åœ¨æ•°ç»„ä¸Šçš„æ“ä½œ
		doc2, _ := ParseString(`{"arr": [1, 2, 3]}`)
		err4 := doc2.Set("/arr", []interface{}{4, 5, 6})
		if err4 != nil {
			t.Errorf("Set array should succeed, got error: %v", err4)
		}

		// æµ‹è¯•åˆ é™¤æ•°ç»„
		err5 := doc2.Delete("/arr")
		if err5 != nil {
			t.Errorf("Delete array should succeed, got error: %v", err5)
		}
	})

	// é’ˆå¯¹ Get() 87.5% è¦†ç›–ç‡
	t.Run("Get_UltimateAttempt", func(t *testing.T) {
		// åˆ›å»ºæœ‰å¤šä¸ªåŒ¹é…çš„ Result
		multiResult := &Result{
			matches: []interface{}{
				map[string]interface{}{"shared_key": "value1", "unique1": "data1"},
				map[string]interface{}{"shared_key": "value2", "unique2": "data2"},
				map[string]interface{}{"shared_key": "value3", "unique3": "data3"},
			},
		}

		// æµ‹è¯•åœ¨å¤šåŒ¹é…ç»“æœä¸Šè·å–å…±åŒé”®
		sharedResult := multiResult.Get("/shared_key")
		if !sharedResult.Exists() {
			t.Error("Get shared key from multi-match should exist")
		}

		// æµ‹è¯•è·å–åªåœ¨æŸäº›åŒ¹é…ä¸­å­˜åœ¨çš„é”®
		uniqueResult := multiResult.Get("/unique2")
		if !uniqueResult.Exists() {
			t.Log("Get unique key from multi-match may not exist (depends on implementation)")
		} else {
			t.Log("Get unique key from multi-match exists")
		}

		// æµ‹è¯•è·å–ä¸å­˜åœ¨çš„é”®
		missingResult := multiResult.Get("/totally_missing")
		if missingResult.Exists() {
			t.Error("Get missing key should not exist")
		}

		// æµ‹è¯•åœ¨åŒ…å«éå¯¹è±¡ç±»å‹çš„å¤šåŒ¹é…ä¸Šè·å–
		mixedResult := &Result{
			matches: []interface{}{
				map[string]interface{}{"key": "object_value"},
				"string_value",
				123,
				[]interface{}{1, 2, 3},
			},
		}

		mixedGet := mixedResult.Get("/key")
		if !mixedGet.Exists() {
			t.Error("Get from mixed types should find object matches")
		}
	})

	// é’ˆå¯¹ materialize 90.9% è¦†ç›–ç‡
	t.Run("Materialize_UltimateAttempt", func(t *testing.T) {
		// æµ‹è¯•å„ç§ JSON ç±»å‹çš„ç‰©åŒ–

		// æµ‹è¯•åŒ…å«æ‰€æœ‰ JSON ç±»å‹çš„å¤æ‚æ–‡æ¡£
		complexJSON := `{
			"string": "test",
			"number": 42.5,
			"integer": 100,
			"boolean_true": true,
			"boolean_false": false,
			"null_value": null,
			"array": [1, "two", true, null, {"nested": "in_array"}],
			"object": {
				"nested_string": "nested",
				"nested_number": 3.14,
				"nested_array": [4, 5, 6],
				"nested_object": {
					"deep": "value"
				}
			},
			"empty_array": [],
			"empty_object": {}
		}`

		doc, err := ParseString(complexJSON)
		if err != nil {
			t.Fatalf("Parse should succeed, got error: %v", err)
		}

		// è§¦å‘ç‰©åŒ–
		err2 := doc.Set("new_field", "trigger_materialize")
		if err2 != nil {
			t.Errorf("Set to trigger materialize should succeed, got error: %v", err2)
		}

		if !doc.IsMaterialized() {
			t.Error("Document should be materialized after Set")
		}

		// åœ¨å·²ç‰©åŒ–çš„æ–‡æ¡£ä¸Šå†æ¬¡æ“ä½œ
		err3 := doc.Set("another_field", map[string]interface{}{
			"complex": []interface{}{1, 2, 3},
		})
		if err3 != nil {
			t.Errorf("Set on materialized document should succeed, got error: %v", err3)
		}
	})

	// æœ€æç«¯çš„ç»¼åˆæµ‹è¯•
	t.Run("ExtremeComprehensiveTest", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªåŒ…å«å„ç§æç«¯æƒ…å†µçš„æ–‡æ¡£
		extremeJSON := `{
			"unicode": "ğŸš€æµ‹è¯•ä¸­æ–‡ğŸ‘",
			"escaped": "line1\nline2\ttab\"quote",
			"numbers": {
				"zero": 0,
				"negative": -123.456,
				"scientific": 1.23e-10,
				"large": 9007199254740991
			},
			"arrays": {
				"empty": [],
				"mixed": [1, "two", true, null, {"nested": "value"}],
				"nested": [[1, 2], [3, 4], [5, 6]]
			},
			"objects": {
				"empty": {},
				"nested": {"level1": {"level2": {"level3": "deep"}}},
				"with_special_keys": {
					"key-with-dashes": 1,
					"key_with_underscores": 2,
					"key with spaces": 3,
					"": "empty_key"
				}
			},
			"edge_cases": {
				"null": null,
				"false": false,
				"true": true,
				"empty_string": "",
				"zero": 0
			}
		}`

		doc, err := ParseString(extremeJSON)
		if err != nil {
			t.Fatalf("Parse extreme JSON should succeed, got error: %v", err)
		}

		// æµ‹è¯•å„ç§æŸ¥è¯¢
		queries := []string{
			"/unicode",
			"/numbers/scientific",
			"/arrays/nested[1]/[0]",
			"/objects/nested/level1/level2/level3",
			"/edge_cases/null",
			"/edge_cases/false",
			"/nonexistent/path",
		}

		for _, query := range queries {
			result := doc.Query(query)
			t.Logf("Query '%s' exists: %v", query, result.Exists())
		}

		// æµ‹è¯•ä¿®æ”¹æ“ä½œ
		modifications := map[string]interface{}{
			"/new_unicode":        "æ–°å¢ä¸­æ–‡å†…å®¹",
			"/numbers/new_number": 999.999,
			"/arrays/new_array":   []interface{}{7, 8, 9},
			"/objects/new_object": map[string]interface{}{"created": true},
			"/deep/new/path/here": "created_deep",
		}

		for path, value := range modifications {
			err := doc.Set(path, value)
			if err != nil {
				t.Logf("Set '%s' failed: %v", path, err)
			} else {
				t.Logf("Set '%s' succeeded", path)
			}
		}

		// éªŒè¯ä¸€äº›è®¾ç½®
		if val, _ := doc.Query("/new_unicode").String(); val != "æ–°å¢ä¸­æ–‡å†…å®¹" {
			t.Errorf("Unicode setting failed, got '%s'", val)
		}
	})
}
